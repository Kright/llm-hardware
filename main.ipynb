{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "prompts, names, runs = {}, {}, []\n",
    "\n",
    "with open(\"main.json.log\", \"r\") as file:\n",
    "    for line in file:\n",
    "        item = json.loads(line)\n",
    "\n",
    "        if item[\"type\"] == \"entity\":\n",
    "            names[item[\"key\"]] = item[\"name\"]\n",
    "        elif item[\"type\"] == \"prompt\":\n",
    "            prompts[item[\"prompt_id\"]] = item\n",
    "        elif item[\"type\"] == \"run\" and \"result\" in item:\n",
    "            result = item[\"result\"]\n",
    "            item[\"text\"] = (result[\"choices\"][0] if \"choices\" in result else result)[\"message\"][\"content\"]\n",
    "            item[\"len\"] = len(item[\"text\"]) + len(prompts[item[\"prompt_id\"]][\"prompt\"])\n",
    "            runs.append(item)\n",
    "\n",
    "df = pd.DataFrame(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OpenAI API</th>\n",
       "      <th>Mac M3 Max 128GB</th>\n",
       "      <th>RTX 4090 24GB</th>\n",
       "      <th>RTX 5090 32GB</th>\n",
       "      <th>RTX 5090 16-core CPU</th>\n",
       "      <th>RTX 5090 96-core CPU</th>\n",
       "      <th>RTX A6000 48GB</th>\n",
       "      <th>RTX 6000Ada 48GB</th>\n",
       "      <th>Dual RTX 4090 24GB</th>\n",
       "      <th>Dual RTX 5090 32GB</th>\n",
       "      <th>A100 SXM4 40GB</th>\n",
       "      <th>Mac M1 8GB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ChatGPT 4o</th>\n",
       "      <td>356 (Δ25%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1-mini</th>\n",
       "      <td>430 (Δ37%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama 2 uncensored 7B (3.8 GB)</th>\n",
       "      <td></td>\n",
       "      <td>351 (Δ76%)</td>\n",
       "      <td>790 (Δ129%)</td>\n",
       "      <td>871 (Δ148%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>580 (Δ97%)</td>\n",
       "      <td>660 (Δ160%)</td>\n",
       "      <td>660 (Δ198%)</td>\n",
       "      <td>855 (Δ131%)</td>\n",
       "      <td>748 (Δ154%)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSeek-R1 7B (4.7 GB)</th>\n",
       "      <td></td>\n",
       "      <td>240 (Δ18%)</td>\n",
       "      <td>665 (Δ22%)</td>\n",
       "      <td>967 (Δ25%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>437 (Δ24%)</td>\n",
       "      <td>536 (Δ23%)</td>\n",
       "      <td>615 (Δ23%)</td>\n",
       "      <td>890 (Δ26%)</td>\n",
       "      <td>623 (Δ20%)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5 14B (9.0 GB)</th>\n",
       "      <td></td>\n",
       "      <td>138 (Δ24%)</td>\n",
       "      <td>381 (Δ30%)</td>\n",
       "      <td>549 (Δ29%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>255 (Δ31%)</td>\n",
       "      <td>322 (Δ28%)</td>\n",
       "      <td>372 (Δ37%)</td>\n",
       "      <td>510 (Δ37%)</td>\n",
       "      <td>368 (Δ29%)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phi-4 14B (9.1 GB)</th>\n",
       "      <td></td>\n",
       "      <td>136 (Δ25%)</td>\n",
       "      <td>418 (Δ31%)</td>\n",
       "      <td>607 (Δ34%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>280 (Δ37%)</td>\n",
       "      <td>343 (Δ33%)</td>\n",
       "      <td>411 (Δ34%)</td>\n",
       "      <td>579 (Δ37%)</td>\n",
       "      <td>405 (Δ36%)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSeek-R1 32B (19 GB)</th>\n",
       "      <td></td>\n",
       "      <td>64 (Δ20%)</td>\n",
       "      <td>185 (Δ22%)</td>\n",
       "      <td>284 (Δ21%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>129 (Δ23%)</td>\n",
       "      <td>151 (Δ23%)</td>\n",
       "      <td>170 (Δ24%)</td>\n",
       "      <td>234 (Δ22%)</td>\n",
       "      <td>185 (Δ23%)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen2.5 32B (19 GB)</th>\n",
       "      <td></td>\n",
       "      <td>65 (Δ22%)</td>\n",
       "      <td>200 (Δ31%)</td>\n",
       "      <td>314 (Δ28%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>135 (Δ31%)</td>\n",
       "      <td>166 (Δ30%)</td>\n",
       "      <td>194 (Δ27%)</td>\n",
       "      <td>253 (Δ32%)</td>\n",
       "      <td>201 (Δ34%)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Command R 35B (18 GB)</th>\n",
       "      <td></td>\n",
       "      <td>86 (Δ33%)</td>\n",
       "      <td>227 (Δ72%)</td>\n",
       "      <td>355 (Δ67%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>156 (Δ39%)</td>\n",
       "      <td>189 (Δ85%)</td>\n",
       "      <td>216 (Δ54%)</td>\n",
       "      <td>313 (Δ61%)</td>\n",
       "      <td>262 (Δ66%)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dolphin Mixtral 8x7B (26 GB)</th>\n",
       "      <td></td>\n",
       "      <td>160 (Δ32%)</td>\n",
       "      <td></td>\n",
       "      <td>403 (Δ108%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>249 (Δ70%)</td>\n",
       "      <td>307 (Δ64%)</td>\n",
       "      <td>340 (Δ55%)</td>\n",
       "      <td>372 (Δ80%)</td>\n",
       "      <td>330 (Δ44%)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeepSeek-R1 70B (42 GB)</th>\n",
       "      <td></td>\n",
       "      <td>28 (Δ18%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>17 (Δ20%)</td>\n",
       "      <td>24 (Δ25%)</td>\n",
       "      <td>66 (Δ24%)</td>\n",
       "      <td>78 (Δ23%)</td>\n",
       "      <td>91 (Δ25%)</td>\n",
       "      <td>129 (Δ23%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama 3.3 70B (42 GB)</th>\n",
       "      <td></td>\n",
       "      <td>29 (Δ23%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>70 (Δ28%)</td>\n",
       "      <td>79 (Δ30%)</td>\n",
       "      <td>95 (Δ31%)</td>\n",
       "      <td>136 (Δ35%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1</th>\n",
       "      <td>264 (Δ37%)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-r1:1.5b</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>165 (Δ19%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3.2:1b</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>122 (Δ6%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                OpenAI API Mac M3 Max 128GB RTX 4090 24GB  \\\n",
       "ChatGPT 4o                      356 (Δ25%)                                  \n",
       "o1-mini                         430 (Δ37%)                                  \n",
       "Llama 2 uncensored 7B (3.8 GB)                   351 (Δ76%)   790 (Δ129%)   \n",
       "DeepSeek-R1 7B (4.7 GB)                          240 (Δ18%)    665 (Δ22%)   \n",
       "Qwen2.5 14B (9.0 GB)                             138 (Δ24%)    381 (Δ30%)   \n",
       "Phi-4 14B (9.1 GB)                               136 (Δ25%)    418 (Δ31%)   \n",
       "DeepSeek-R1 32B (19 GB)                           64 (Δ20%)    185 (Δ22%)   \n",
       "Qwen2.5 32B (19 GB)                               65 (Δ22%)    200 (Δ31%)   \n",
       "Command R 35B (18 GB)                             86 (Δ33%)    227 (Δ72%)   \n",
       "Dolphin Mixtral 8x7B (26 GB)                     160 (Δ32%)                 \n",
       "DeepSeek-R1 70B (42 GB)                           28 (Δ18%)                 \n",
       "Llama 3.3 70B (42 GB)                             29 (Δ23%)                 \n",
       "o1                              264 (Δ37%)                                  \n",
       "deepseek-r1:1.5b                                                            \n",
       "llama3.2:1b                                                                 \n",
       "\n",
       "                               RTX 5090 32GB RTX 5090 16-core CPU  \\\n",
       "ChatGPT 4o                                                          \n",
       "o1-mini                                                             \n",
       "Llama 2 uncensored 7B (3.8 GB)   871 (Δ148%)                        \n",
       "DeepSeek-R1 7B (4.7 GB)           967 (Δ25%)                        \n",
       "Qwen2.5 14B (9.0 GB)              549 (Δ29%)                        \n",
       "Phi-4 14B (9.1 GB)                607 (Δ34%)                        \n",
       "DeepSeek-R1 32B (19 GB)           284 (Δ21%)                        \n",
       "Qwen2.5 32B (19 GB)               314 (Δ28%)                        \n",
       "Command R 35B (18 GB)             355 (Δ67%)                        \n",
       "Dolphin Mixtral 8x7B (26 GB)     403 (Δ108%)                        \n",
       "DeepSeek-R1 70B (42 GB)                                 17 (Δ20%)   \n",
       "Llama 3.3 70B (42 GB)                                               \n",
       "o1                                                                  \n",
       "deepseek-r1:1.5b                                                    \n",
       "llama3.2:1b                                                         \n",
       "\n",
       "                               RTX 5090 96-core CPU RTX A6000 48GB  \\\n",
       "ChatGPT 4o                                                           \n",
       "o1-mini                                                              \n",
       "Llama 2 uncensored 7B (3.8 GB)                          580 (Δ97%)   \n",
       "DeepSeek-R1 7B (4.7 GB)                                 437 (Δ24%)   \n",
       "Qwen2.5 14B (9.0 GB)                                    255 (Δ31%)   \n",
       "Phi-4 14B (9.1 GB)                                      280 (Δ37%)   \n",
       "DeepSeek-R1 32B (19 GB)                                 129 (Δ23%)   \n",
       "Qwen2.5 32B (19 GB)                                     135 (Δ31%)   \n",
       "Command R 35B (18 GB)                                   156 (Δ39%)   \n",
       "Dolphin Mixtral 8x7B (26 GB)                            249 (Δ70%)   \n",
       "DeepSeek-R1 70B (42 GB)                   24 (Δ25%)      66 (Δ24%)   \n",
       "Llama 3.3 70B (42 GB)                                    70 (Δ28%)   \n",
       "o1                                                                   \n",
       "deepseek-r1:1.5b                                                     \n",
       "llama3.2:1b                                                          \n",
       "\n",
       "                               RTX 6000Ada 48GB Dual RTX 4090 24GB  \\\n",
       "ChatGPT 4o                                                           \n",
       "o1-mini                                                              \n",
       "Llama 2 uncensored 7B (3.8 GB)      660 (Δ160%)        660 (Δ198%)   \n",
       "DeepSeek-R1 7B (4.7 GB)              536 (Δ23%)         615 (Δ23%)   \n",
       "Qwen2.5 14B (9.0 GB)                 322 (Δ28%)         372 (Δ37%)   \n",
       "Phi-4 14B (9.1 GB)                   343 (Δ33%)         411 (Δ34%)   \n",
       "DeepSeek-R1 32B (19 GB)              151 (Δ23%)         170 (Δ24%)   \n",
       "Qwen2.5 32B (19 GB)                  166 (Δ30%)         194 (Δ27%)   \n",
       "Command R 35B (18 GB)                189 (Δ85%)         216 (Δ54%)   \n",
       "Dolphin Mixtral 8x7B (26 GB)         307 (Δ64%)         340 (Δ55%)   \n",
       "DeepSeek-R1 70B (42 GB)               78 (Δ23%)          91 (Δ25%)   \n",
       "Llama 3.3 70B (42 GB)                 79 (Δ30%)          95 (Δ31%)   \n",
       "o1                                                                   \n",
       "deepseek-r1:1.5b                                                     \n",
       "llama3.2:1b                                                          \n",
       "\n",
       "                               Dual RTX 5090 32GB A100 SXM4 40GB  Mac M1 8GB  \n",
       "ChatGPT 4o                                                                    \n",
       "o1-mini                                                                       \n",
       "Llama 2 uncensored 7B (3.8 GB)        855 (Δ131%)    748 (Δ154%)              \n",
       "DeepSeek-R1 7B (4.7 GB)                890 (Δ26%)     623 (Δ20%)              \n",
       "Qwen2.5 14B (9.0 GB)                   510 (Δ37%)     368 (Δ29%)              \n",
       "Phi-4 14B (9.1 GB)                     579 (Δ37%)     405 (Δ36%)              \n",
       "DeepSeek-R1 32B (19 GB)                234 (Δ22%)     185 (Δ23%)              \n",
       "Qwen2.5 32B (19 GB)                    253 (Δ32%)     201 (Δ34%)              \n",
       "Command R 35B (18 GB)                  313 (Δ61%)     262 (Δ66%)              \n",
       "Dolphin Mixtral 8x7B (26 GB)           372 (Δ80%)     330 (Δ44%)              \n",
       "DeepSeek-R1 70B (42 GB)                129 (Δ23%)                             \n",
       "Llama 3.3 70B (42 GB)                  136 (Δ35%)                             \n",
       "o1                                                                            \n",
       "deepseek-r1:1.5b                                                  165 (Δ19%)  \n",
       "llama3.2:1b                                                        122 (Δ6%)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"metric\"] = df[\"len\"] / df[\"elapsed_time\"]\n",
    "\n",
    "df_std = df.groupby([\"runner\", \"model\"])[\"metric\"].agg([\"median\", \"std\"])\n",
    "df_std[\"combined\"] = df_std.apply(lambda row: f\"{row['median']:.0f} (Δ{100 * row['std'] / row['median']:.0f}%)\", axis=1)\n",
    "table = df_std.reset_index().pivot(index=\"model\", columns=\"runner\", values=\"combined\")\n",
    "\n",
    "table.index.name = None\n",
    "table.columns.name = None\n",
    "name_order = list(names.keys())\n",
    "\n",
    "def sort_key(value):\n",
    "    return name_order.index(value) if value in name_order else float('inf')\n",
    "\n",
    "table = table.loc[sorted(table.index, key=sort_key)]\n",
    "table = table[sorted(table.columns, key=sort_key)]\n",
    "table.index = table.index.map(lambda x: names.get(x, x))\n",
    "table.columns = table.columns.map(lambda x: names.get(x, x))\n",
    "table = table.applymap(lambda x: x if pd.notna(x) else \"\")\n",
    "\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
